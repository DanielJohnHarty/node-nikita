// Generated by CoffeeScript 2.5.0
// `nikita.file.types.hfile`

// HFile is an XML format used accros Hadoop components which contains keys and
// value properties.

// ## Options

// * `merge` (boolean)   
//   Read the target if it exists and merge its content, optional.
// * `source` (object, string)   
//   Default configuration properties or the path to a default configuration file
//   to get initial value from, optional.
// * `target` (string)   
//   Configuration file where to write, required.
// * `properties` (object)   
//   Configuration properties to write, required.
// * `transform` (function)   
//   User defined function used to transform properties.

// ## Source Code
var builder, parse, stringify, xmldom;

module.exports = function({options}) {
  var fnl_props, org_props;
  fnl_props = {};
  org_props = {};
  if (options.transform == null) {
    options.transform = null;
  }
  if (options.encoding == null) {
    options.encoding = 'utf8';
  }
  if ((options.transform != null) && typeof options.transform !== 'function') {
    throw Error("Invalid options: \"transform\"");
  }
  this.call(function(_, callback) {
    this.log({
      message: `Read target properties from '${options.target}'`,
      level: 'DEBUG',
      module: '@nikita/filetypes/lib/hfile'
    });
    // Populate org_props and, if merge, fnl_props
    return this.fs.readFile({
      encoding: options.encoding,
      target: options.target
    }, function(err, {data}) {
      var k, v;
      if ((err != null ? err.code : void 0) === 'ENOENT') {
        return callback();
      }
      if (err) {
        return callback(err);
      }
      org_props = parse(data);
      if (options.merge) {
        fnl_props = {};
        for (k in org_props) {
          v = org_props[k];
          fnl_props[k] = v;
        }
      }
      return callback();
    });
  });
  this.call(function(_, callback) {
    if (!options.source) {
      return callback();
    }
    if (typeof options.source !== 'string') {
      return callback();
    }
    this.log({
      message: `Read source properties from ${options.source}`,
      level: 'DEBUG',
      module: '@nikita/filetypes/lib/hfile'
    });
    // Populate options.source
    return this.fs.readFile({
      encoding: options.encoding,
      target: options.target
    }, options.local ? {
      ssh: null
    } : {}, function(err, {data}) {
      if (err) {
        return callback(err);
      }
      options.source = parse(data);
      return callback();
    });
  });
  this.call(function() {
    var k, ref, results, v;
    if (!options.source) {
      return;
    }
    // Note, source properties overwrite current ones by source, not sure
    // if this is the safest approach
    this.log({
      message: "Merge source properties",
      level: 'DEBUG',
      module: '@nikita/filetypes/lib/hfile'
    });
    ref = options.source;
    results = [];
    for (k in ref) {
      v = ref[k];
      if (typeof v === 'number') {
        v = `${v}`;
      }
      if (fnl_props[k] === void 0 || fnl_props[k] === null) {
        results.push(fnl_props[k] = v);
      } else {
        results.push(void 0);
      }
    }
    return results;
  });
  this.call(function() {
    var k, ref, results, v;
    this.log({
      message: "Merge user properties",
      level: 'DEBUG',
      module: '@nikita/filetypes/lib/hfile'
    });
    ref = options.properties;
    results = [];
    for (k in ref) {
      v = ref[k];
      if (typeof v === 'number') {
        v = `${v}`;
      }
      if (typeof v === 'undefined' || v === null) {
        results.push(delete fnl_props[k]);
      } else if (Array.isArray(v)) {
        results.push(fnl_props[k] = v.join(','));
      } else if (typeof v !== 'string') {
        throw Error(`Invalid value type '${typeof v}' for property '${k}'`);
      } else {
        results.push(fnl_props[k] = v);
      }
    }
    return results;
  });
  this.call(function() {
    if (!options.transform) {
      return;
    }
    return fnl_props = options.transform(fnl_props);
  });
  this.call(function() {
    var i, j, k, keys, l, len, len1, len2, ref, ref1, results;
    keys = {};
    ref = Object.keys(org_props);
    for (i = 0, len = ref.length; i < len; i++) {
      k = ref[i];
      keys[k] = true;
    }
    ref1 = Object.keys(fnl_props);
    for (j = 0, len1 = ref1.length; j < len1; j++) {
      k = ref1[j];
      if (keys[k] == null) {
        keys[k] = true;
      }
    }
    keys = Object.keys(keys);
    results = [];
    for (l = 0, len2 = keys.length; l < len2; l++) {
      k = keys[l];
      if (org_props[k] === fnl_props[k]) {
        continue;
      }
      results.push(this.log({
        message: `Property '${k}' was '${org_props[k]}' and is now '${fnl_props[k]}'`,
        level: 'WARN',
        module: '@nikita/filetypes/lib/hfile'
      }));
    }
    return results;
  });
  return this.call(function() {
    options.content = stringify(fnl_props);
    options.source = null;
    options.header = null;
    return this.file(options);
  });
};

// ## `parse(xml, [property])`

// Parse an xml document and retrieve one or multiple properties.

// Retrieve all properties: `properties = parse(xml)`
// Retrieve a property: `value = parse(xml, property)`
parse = function(markup, property) {
  var child, doc, i, j, len, len1, name, properties, propertyChild, ref, ref1, ref2, ref3, ref4, ref5, value;
  properties = {};
  doc = new xmldom.DOMParser().parseFromString(markup);
  ref = doc.documentElement.childNodes;
  for (i = 0, len = ref.length; i < len; i++) {
    propertyChild = ref[i];
    if (((ref1 = propertyChild.tagName) != null ? ref1.toUpperCase() : void 0) !== 'PROPERTY') {
      continue;
    }
    name = value = null;
    ref2 = propertyChild.childNodes;
    for (j = 0, len1 = ref2.length; j < len1; j++) {
      child = ref2[j];
      if (((ref3 = child.tagName) != null ? ref3.toUpperCase() : void 0) === 'NAME') {
        name = child.childNodes[0].nodeValue;
      }
      if (((ref4 = child.tagName) != null ? ref4.toUpperCase() : void 0) === 'VALUE') {
        value = ((ref5 = child.childNodes[0]) != null ? ref5.nodeValue : void 0) || '';
      }
    }
    if (property && name === property && (value != null)) {
      return value;
    }
    if (name && (value != null)) {
      properties[name] = value;
    }
  }
  return properties;
};

// ## `stringify(properties)`

// Convert a property object into a valid Hadoop XML markup. Properties are
// ordered by name.

// Convert an object into a string:

// ```
// markup = stringify({
//   'fs.defaultFS': 'hdfs://namenode:8020'
// });
// ```

// Convert an array into a string:

// ```
// stringify([{
//   name: 'fs.defaultFS', value: 'hdfs://namenode:8020'
// }])
// ```
stringify = function(properties) {
  var i, j, k, ks, len, len1, markup, name, property, value;
  markup = builder.create('configuration', {
    version: '1.0',
    encoding: 'UTF-8'
  });
  if (Array.isArray(properties)) {
    properties.sort(function(el1, el2) {
      return el1.name > el2.name;
    });
    for (i = 0, len = properties.length; i < len; i++) {
      ({name, value} = properties[i]);
      property = markup.ele('property');
      property.ele('name', name);
      property.ele('value', value);
    }
  } else {
    ks = Object.keys(properties);
    ks.sort();
    for (j = 0, len1 = ks.length; j < len1; j++) {
      k = ks[j];
      property = markup.ele('property');
      property.ele('name', k);
      property.ele('value', properties[k]);
    }
  }
  return markup.end({
    pretty: true
  });
};

// ## Dependencies
xmldom = require('xmldom');

builder = require('xmlbuilder');
